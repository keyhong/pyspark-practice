{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f600107",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c486ed53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/26 11:10:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[*] appName=RDD_practice>\n"
     ]
    }
   ],
   "source": [
    "# pyspark 연결하기 (SparkSession이 아닌, SparkContext로 연결하는 고전적인 방법임.)\n",
    "conf = SparkConf().setAppName(\"RDD_practice\").setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf=conf)\n",
    "print(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480f0a11",
   "metadata": {},
   "source": [
    "# Part1: RDD 생성 및 기본 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489037f8",
   "metadata": {},
   "source": [
    "# RDD를 생성하는 두 가지 방법:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aadcb45",
   "metadata": {},
   "source": [
    "1. 드라이버 프로그램에서 기존의 컬렉션을 Parallelizing 하는 방법\n",
    "2. 공유 파일 시스템, HDFS, HBase, Hadoop InputFormat을 제공하는 데이터 소스 등과 같은 외부 데이터 저장소를 참조하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ba051607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 37, 21, 22, 6, 17, 15, 28, 38, 30]\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 데이터 생성\n",
    "import random\n",
    "random_list = random.sample(range(0, 40), 10)\n",
    "print(random_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d4dc0807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 37, 21, 22, 6, 17, 15, 28, 38, 30]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RDD 생성\n",
    "rdd1 = sc.parallelize(random_list, 4)\n",
    "rdd1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "be3098a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumSlices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Distribute a local Python collection to form an RDD. Using xrange\n",
       "is recommended if the input represents a range for performance.\n",
       "\n",
       ">>> sc.parallelize([0, 2, 3, 4, 6], 5).glom().collect()\n",
       "[[0], [2], [3], [4], [6]]\n",
       ">>> sc.parallelize(xrange(0, 6, 2), 5).glom().collect()\n",
       "[[], [0], [], [2], [4]]\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/local/lib/python3.9/dist-packages/pyspark/context.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sc.parallelize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ff54a623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[[7, 37], [21, 22], [6, 17], [15, 28, 38, 30]]\n",
      "The two partitions [[7, 37], [21, 22]]\n",
      "The last partition [15, 28, 38, 30]\n"
     ]
    }
   ],
   "source": [
    "# 전체 파티션 수 조회\n",
    "print(rdd1.getNumPartitions())\n",
    "\n",
    "# 파티션별 분산된 데이터 조회\n",
    "print(rdd1.glom().collect())\n",
    "\n",
    "# 파티션별 분산된 데이터 중 2개의 파티션만 보기\n",
    "print(\"The two partitions\", rdd1.glom().take(2))\n",
    "\n",
    "# 마지막 파티션 출력\n",
    "print(\"The last partition\", rdd1.glom().collect()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd5b0fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count() : RDD 전체 element 개수\n",
    "rdd1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac37f9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first() : 첫 번쨰 파티션의 첫 번째 element 값\n",
    "rdd1.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03142b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 : [38]\n",
      "Top 2 : [38, 37]\n"
     ]
    }
   ],
   "source": [
    "# top(): 값이 높은 상위 N개의 elemenet 출력\n",
    "# drive 프로세스에 모든 element를 보낸 후, 정렬(sort) 후 값을 반환하므로 데이터의 사이즈가 크면 사용에 주의가 필요하다.\n",
    "print(\"Top 1 :\", rdd1.top(1))\n",
    "print(\"Top 2 :\", rdd1.top(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5eb29c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 20, 37, 33, 5, 30, 34, 38, 26, 19]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distinct() : 중복을 제거한 element 반환\n",
    "rdd1.distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cd33d796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def function map : [[15, 63], [60, 114], [102, 93], [18, 105, 117, 81]]\n",
      "lambda function map : [[15, 63], [60, 114], [102, 93], [18, 105, 117, 81]]\n"
     ]
    }
   ],
   "source": [
    "def myfunc(item):\n",
    "    return (item+1) * 3\n",
    "\n",
    "# map(): 각 elemnt에 function을 적용한 결과를 RDD로 반환 (파티션의 수는 변하지 않는다.)\n",
    "rdd_map = rdd1.map(myfunc)\n",
    "print(\"def function map :\", rdd_map.glom().collect())\n",
    "\n",
    "# map의 인자로 lambda(익명함수)도 사용 가능하다.\n",
    "rdd_map = rdd1.map(lambda item: (item+1) * 3)\n",
    "print(\"lambda function map :\", rdd_map.glom().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "42643b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [21], [6], [15, 30]]\n",
      "After filtering count : 4\n",
      "Repartition : [[21, 6, 15, 30]]\n"
     ]
    }
   ],
   "source": [
    "# filter(): element를 조건(function)에 부합하는 element만 필터링하여 RDD 반환 (파티션의 수는 변하지 않는다. 따라서, empty한 파티션이 발생 가능하다.)\n",
    "# empty한 파티션은 GC(Garbage Collect) 기술인 repartition/coalese릍 통해 차후 제거 가능하다.\n",
    "rdd_filter = rdd1.filter(lambda x: x%3==0)\n",
    "print(rdd_filter.glom().collect())\n",
    "\n",
    "print(\"After filtering count :\", rdd_filter.count())\n",
    "print(\"Repartition :\", rdd_filter.repartition(1).glom().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4c5e1c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatMap Collect:  [9, 12, 39, 42, 23, 26, 24, 27, 8, 11, 19, 22, 17, 20, 30, 33, 40, 43, 32, 35]\n",
      "map Collect:  [[9, 12], [39, 42], [23, 26], [24, 27], [8, 11], [19, 22], [17, 20], [30, 33], [40, 43], [32, 35]] \n",
      "\n",
      "flatMap glom collect [[9, 12, 39, 42], [23, 26, 24, 27], [8, 11, 19, 22], [17, 20, 30, 33, 40, 43, 32, 35]]\n",
      "map glom collect:  [[[9, 12], [39, 42]], [[23, 26], [24, 27]], [[8, 11], [19, 22]], [[17, 20], [30, 33], [40, 43], [32, 35]]] \n",
      "\n",
      "flatMap Partition Num: 4\n",
      "map Partition Num: 4\n"
     ]
    }
   ],
   "source": [
    "# flatMap(): 파티션별 모든 element를 하나의 단일 컬렉션으로 반환한다. (파티션 수가 변하는 것이 아니다. 파티션 내부의 차원을 한 단계 flat하게 만든다.)\n",
    "rdd_flatmap = rdd1.flatMap(lambda x: [x+2, x+5])\n",
    "\n",
    "# map()과 비교하기\n",
    "rdd_map = rdd1.map(lambda x: [x+2, x+5])\n",
    "\n",
    "# 비교 시작\n",
    "print(\"flatMap Collect: \", rdd_flatmap.collect())\n",
    "print(\"map Collect: \", rdd_map.collect(), \"\\n\")\n",
    "\n",
    "print(\"flatMap glom collect\", rdd_flatmap.glom().collect())\n",
    "print(\"map glom collect: \", rdd_map.glom().collect(), \"\\n\")\n",
    "\n",
    "print(\"flatMap Partition Num:\", rdd_flatmap.getNumPartitions())\n",
    "print(\"map Partition Num:\", rdd_map.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ba800543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduce(): 각 파티션별 배열(1차원)의 element에 대해 function을 수행한다. 파티션별 function의 return 값에 대해 파티션 전체에 대한 reduce를 계속 실행한다.\n",
    "# reduce()는 transformation이 아닌, action 함수이다.\n",
    "\n",
    "# flatMap glom collect: [[9, 12, 39, 42], [23, 26, 24, 27], [8, 11, 19, 22], [17, 20, 30, 33, 40, 43, 32, 35]] 라면,\n",
    "# step1 : [((9+12)+39)+42], [((23+26)+24)+27], [((8+11)+19)+22], [((((((17+20)+30)+33)+40)+43)+32)+35]]\n",
    "# step2 : (([102] + [100]) + [60]) + [250]\n",
    "# Return : 512\n",
    "\n",
    "rdd_flatmap.reduce(lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "76330af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38, 6, 22.1, 10.66, 221]\n"
     ]
    }
   ],
   "source": [
    "# 기술 통계 (Descriptive statistic)\n",
    "print([rdd1.max(), rdd1.min(), rdd1.mean(), round(rdd1.stdev(), 2), rdd1.sum()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "89397283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdd1 glom collect: [[7, 37], [21, 22], [6, 17], [15, 28, 38, 30]]\n",
      "rdd1 mapPartition: [44, 43, 23, 111]\n",
      "rdd1 glom Partition: [[44], [43], [23], [111]]\n"
     ]
    }
   ],
   "source": [
    "# mapPartitions(): 파티션별 function을 하여 특정 결과를 반환한다. action에 reduce가 있다면, transformation에는 mapPartition이라고 생각하면 쉽다.\n",
    "# 각 파티션의 element에 대해 fuct을 적용한 중간 결과(yield)를 다음 element의 func 연산을 할 떄 사용하므로, 제너레이터에 사용하는 yield를 사용해야 한다!\n",
    "\n",
    "def myfunc(partition):\n",
    "    sumatition = 0\n",
    "    \n",
    "    for item in partition:\n",
    "        sumatition = sumatition + item\n",
    "        \n",
    "    yield sumatition\n",
    "\n",
    "print(\"rdd1 glom collect:\", rdd1.glom().collect())\n",
    "print(\"rdd1 mapPartition:\", rdd1.mapPartitions(myfunc).collect())\n",
    "print(\"rdd1 glom Partition:\", rdd1.mapPartitions(myfunc).glom().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c949d3e9",
   "metadata": {},
   "source": [
    "# Part2: Advanced RDD Transformations and Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7508b730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDD 1: [7, 37, 21, 22, 6, 17, 15, 28, 38, 30]\n",
      "RDD 2: [1, 14, 37, 20, 28, 10, 13, 3]\n",
      "RDD union: [7, 37, 21, 22, 6, 17, 15, 28, 38, 30, 1, 14, 37, 20, 28, 10, 13, 3]\n",
      "RDD Partition Num: 6\n"
     ]
    }
   ],
   "source": [
    "# union(): 두 RDD를 결합하여 새로운 RDD를 반환한다. 결합한 RDD의 파티션 수는 결합에 사용된 RDD의 파티션의 총 합과 같다.\n",
    "\n",
    "print(\"RDD 1:\", rdd1.collect())\n",
    "\n",
    "rdd2 = sc.parallelize([1, 14, 37, 20, 28, 10, 13, 3], 2)\n",
    "print(\"RDD 2:\", rdd2.collect())\n",
    "\n",
    "rdd_union = rdd1.union(rdd2)\n",
    "print(\"RDD union:\", rdd_union.collect())\n",
    "\n",
    "print(\"RDD Partition Num:\", rdd_union.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "dfed0149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDD intersection: [37, 28]\n",
      "RDD intersection glom collect: [[], [37], [], [], [28], []]\n",
      "RDD Partition Num: 6\n"
     ]
    }
   ],
   "source": [
    "# intersection(): 두 RDD의 공통된 element만 추출하여 새로운 RDD를 반환한다. 교차시킨 RDD의 파티션 수는 교차에 사용된 RDD의 파티션의 총 합과 같다.\n",
    "rdd_intersection = rdd1.intersection(rdd2)\n",
    "\n",
    "print(\"RDD intersection:\", rdd_intersection.collect())\n",
    "print(\"RDD intersection glom collect:\" , rdd_intersection.glom().collect())\n",
    "print(\"RDD Partition Num:\", rdd_intersection.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0d34aa66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find empty partitions\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for item in rdd_intersection.glom().collect():\n",
    "    if len(item) == 0:\n",
    "        counter += 1\n",
    "\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "570c0f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[37, 28]]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coalesce(numPartitions): 파티션의 수를 줄인다. \n",
    "rdd_intersection.coalesce(1).glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "dd68555f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22, 17, 28, 30, 21]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# takeSample(withReplacement, num, [seed]): 무작위로 데이터를 추출하여 반환한다.\n",
    "# collect()와 마찬가지로, parallel 하지 않고 drive 메모리에 모든 element를 모아 랜덤 추출하기 때문에 스파크 클러스터가 손상 될 수 있어 사용에 주의가 필요하다.\n",
    "rdd1.takeSample(False, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "68d3b10d79c6e02d0d1f7bb5595fc6acdd9cd892dc842c813ff1c5403a22a80c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
